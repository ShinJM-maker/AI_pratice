{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# colab을 이용한 Natural Language Processing(NLP) 실습\n",
        "\n",
        "🎯 학습 목표 : colab 환경에서 NLP 모델 학습 코드를 실행하고 결과를 확인할 수 있다.\n",
        "\n",
        "- 실습 재료\n",
        "\n",
        "| 항목 | 상세 |\n",
        "| ---- | ---- |\n",
        "| 🗂️ 데이터 | AI-HUB의 감성 대화 말뭉치 중 샘플 데이터 |\n",
        "| 🤖 NLP 언어 모델 | GPT-2 (Generative pre-trained transformer-2) |\n",
        "| 🏗️ NLP 학습 프레임워크 | torch |\n",
        "| 🐍 프로그래밍 언어 | Python |\n",
        "| 👩‍💻 프로그래밍 환경 | Colab |\n",
        "\n",
        "\n",
        "- colab에서 코드 실행 방법은 다음 그림을 참조해주시기 바랍니다.\n",
        "    ![](https://i.imgur.com/0GoFr7q.png)"
      ],
      "metadata": {
        "id": "7qnLQFBp6paB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 데이터 로딩 및 전처리\n",
        "\n",
        "이번 실습에서 사용되는 데이터는 AI-HUB의 치매 감성 대화 말뭉치 중 샘플 데이터 집합 중 인지기능 데이터의 샘플 자료를 이용합니다.\n",
        "\n",
        "실습 데이터 집합에 대한 명세는 다음과 같습니다.\n",
        "\n",
        "- 데이터 개수 : 19,920개\n",
        "- 주요 항목\n",
        "  - persona: 대화자의 페르소나 정보\n",
        "  - emotion: 감정 정보(우리가 예측하고자 하는 타겟)\n",
        "  - talk: 대화 내용\n",
        "    - content: 대화 내용 (HS01, SS01, ...)\n",
        "\n",
        "우리가 원하는 것은 각 대화(HS01, SS01, ...)의 내용과 그에 해당하는 감정(emotion의 type)입니다. 따라서 이 정보를 추출하여 전처리를 진행하겠습니다."
      ],
      "metadata": {
        "id": "hYpgisno_bYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ShinJM-maker/pratice_GPT2.git"
      ],
      "metadata": {
        "id": "TOSesHRI2wgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZn-dCQFTnb5"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# 로컬에서 JSON 파일 읽기\n",
        "file_path = \"/content/pratice_GPT2/감성대화말뭉치(최종데이터)_Validation.json\"  # 실제 파일 경로로 변경해주세요\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Extracting relevant data for emotion classification\n",
        "texts = []\n",
        "labels = []\n",
        "\n",
        "for entry in data:\n",
        "    emotion = entry['profile']['emotion']['type']\n",
        "\n",
        "    # Extracting all the dialogues\n",
        "    for key, dialogue in entry['talk']['content'].items():\n",
        "        if key.startswith('HS'):  # We'll only consider human dialogues for simplicity\n",
        "            texts.append(dialogue)\n",
        "            labels.append(emotion)\n",
        "\n",
        "# Checking the first few entries\n",
        "texts[100:105], labels[100:105]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 코드의 실행으로 데이터가 성공적으로 추출되었습니다. 각 대화 내용(texts)과 해당 대화의 감정 라벨(labels)을 확인할 수 있습니다. 데이터를 학습용과 검증용으로 나누겠습니다."
      ],
      "metadata": {
        "id": "vJ-TpYWnAoVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the data into training and validation sets\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "len(train_texts), len(val_texts)\n"
      ],
      "metadata": {
        "id": "rFak2t41UMFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터를 학습용(15,936개)과 검증용(3,984개)으로 나눴습니다.\n",
        "\n",
        "아래는 AI-HUB의 감성 대화 말뭉치의 라벨 목록입니다.\n",
        "\n",
        "![Image Alt Text](https://drive.google.com/uc?export=view&id=1fzxQIpz21nOc8G1nP8AFuERijwoUodaV)\n",
        "\n",
        "\n",
        "아래는 데이터셋의 라벨별 개수를 시각화 하는 코드입니다."
      ],
      "metadata": {
        "id": "aWbTWXZg_da0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Count the occurrences of each label in the training set\n",
        "label_distribution = Counter(train_labels)\n",
        "#print(label_distribution)\n",
        "sorted_label_distribution = dict(sorted(label_distribution.items(), key=lambda item: int(item[0][1:])))\n",
        "print(sorted_label_distribution)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract labels and their counts\n",
        "labels = list(sorted_label_distribution.keys())\n",
        "counts = list(sorted_label_distribution.values())\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(15, 7))  # Set the figure size for better visibility\n",
        "plt.bar(labels, counts, color='blue')\n",
        "plt.xlabel('Emotion Labels')\n",
        "plt.ylabel('Number of Occurrences')\n",
        "plt.title('Distribution of Emotion Labels')\n",
        "plt.xticks(rotation=90)  # Rotate x-axis labels for better visibility\n",
        "plt.tight_layout()  # Adjust layout for better visibility\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ntFAqWscy6ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. GPT-2 모델 및 토크나이저 로딩\n",
        "\n",
        "다음 단계로, GPT-2 모델 및 토크나이저를 로딩하겠습니다. Google Colab에서 실행할 때, 라이브러리 설치 및 모델 로딩을 위한 코드를 제공하겠습니다.\n",
        "\n",
        "본 과정에서는 다음을 수행합니다.\n",
        "\n",
        "1. 필요한 라이브러리 설치\n",
        "2. GPT-2 토크나이저 로딩\n",
        "3. 라벨 인코딩 및 텍스트 토큰화\n",
        "4. PyTorch 데이터셋으로 변환\n",
        "5. GPT-2 모델 로딩 및 분류 헤드 추가\n",
        "6. 학습 설정\n",
        "\n"
      ],
      "metadata": {
        "id": "H4CQmnjWA0_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래의 코드에서 필요한 라이브러리를 설치합니다.\n",
        "1. accelerate\n",
        "2. transformers"
      ],
      "metadata": {
        "id": "cMoetBzaEHwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall accelerate -y\n",
        "!pip install accelerate\n",
        "\n",
        "!pip install transformers[torch] -U"
      ],
      "metadata": {
        "id": "y4XtwJyOEGjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "라이브러리를 설치했다면 이제 토크나이저를 로딩하고 학습을 위한 설정을 진행합니다.\n",
        "\n",
        "아래 코드를 통해 감정 분류 작업을 위해 GPT-2 모델을 미세 조정하는 방법을 배웁니다.\n",
        "우리는 GPT-2 모델을 활용하고 분류 작업을 위해 시퀀스 분류 헤드를 추가함으로써 이를 적용시킬 것입니다."
      ],
      "metadata": {
        "id": "stX8DKPLEPG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, AdamW\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 토큰화: GPT-2 토큰화기를 로드하여 시작합니다.\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "#라벨 인코딩: 분류 작업을 위해 문자열 라벨을 정수로 변환해야 합니다.\n",
        "\n",
        "combined_labels = train_labels + val_labels\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(combined_labels)\n",
        "\n",
        "train_enc_labels = label_encoder.transform(train_labels)\n",
        "val_enc_labels = label_encoder.transform(val_labels)\n",
        "\n",
        "# 텍스트 인코딩: GPT-2 토큰화기를 사용하여 텍스트 데이터를 모델이 이해할 수 있는 형식으로 변환합니다.\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=100)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=100)\n",
        "\n",
        "# PyTorch 데이터셋 생성: 데이터가 토큰화되면 이를 PyTorch Dataset으로 변환해야 합니다.\n",
        "class EmotionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = EmotionDataset(train_encodings, train_enc_labels)\n",
        "val_dataset = EmotionDataset(val_encodings, val_enc_labels)\n",
        "\n",
        "# 모델 초기화: 시퀀스 분류 헤드가 있는 사전 훈련된 GPT-2 모델을 로드합니다.\n",
        "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2-medium\", num_labels=len(set(combined_labels)))\n",
        "\n",
        "# 모델 구성: 토큰화기에 패딩 토큰을 설정한 것처럼 모델에게도 이 패딩 토큰에 대해 알려야 합니다.\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 훈련 설정: 우리는 오류를 최소화하기 위해 훈련 중에 모델의 가중치를 조정하는 최적화기를 정의합니다.\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8)\n"
      ],
      "metadata": {
        "id": "ClpIt17vURwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. GPT-2를 활용한 감정 분류 모델 훈련 및 평가\n",
        "\n",
        "이 섹션에서는 GPT-2 감정 분류 모델을 훈련하고 평가하는 과정을 다룹니다. 우리는 훈련 데이터를 활용하여 모델을 미세 조정하고, 검증 데이터를 사용하여 모델의 성능을 평가합니다.\n",
        "\n",
        "본 과정에서는 다음을 수행합니다.\n",
        "\n",
        "1. 훈련 모드 설정\n",
        "2. 훈련 루프\n",
        "3. 평가 모드 설정\n",
        "4. 모델 평가\n",
        "5. 모델 및 토큰화기 저장\n",
        "\n",
        "원래는 여러 학습 epoch를 진행해야 하지만, 실습을 간략하게 진행하기 위해 1 epoch와 10 batch만으로 학습을 수행합니다."
      ],
      "metadata": {
        "id": "xWO71tL3B7MD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# 보다 빠른 학습을 위해 1 epoch만 실행하는 학습 루프\n",
        "for epoch in range(1):\n",
        "    model.train()  # 모델을 학습 모드로 설정\n",
        "    total_train_loss = 0\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        optimizer.zero_grad()  # 그라디언트 초기화\n",
        "        # 입력 데이터 GPU 사용 가능 여부에 따라 설정\n",
        "        inputs = {k: v.to(\"cuda\" if torch.cuda.is_available() else \"cpu\") for k, v in batch.items()}\n",
        "        outputs = model(**inputs)  # 모델에 입력 데이터 전달\n",
        "        loss = outputs.loss  # 손실 값\n",
        "        total_train_loss += loss.item()  # 총 학습 손실에 추가\n",
        "        loss.backward()  # 역전파\n",
        "        optimizer.step()  # 최적화 수행\n",
        "\n",
        "        print(f\"Batch {batch_idx}, Training Loss: {total_train_loss / (batch_idx + 1)}\")\n",
        "        if batch_idx == 10:\n",
        "            break\n",
        "\n",
        "    # 모델 평가\n",
        "    model.eval()  # 모델을 평가 모드로 설정\n",
        "    total_val_loss = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    batch_count = 0  # 배치 수 제한용 변수\n",
        "    with torch.no_grad():  # 그라디언트 계산 비활성화\n",
        "        for batch in val_loader:\n",
        "            batch_count += 1\n",
        "            # 디버깅을 위해 처음 5개 배치만 처리\n",
        "            if batch_count > 5:\n",
        "                break\n",
        "\n",
        "            print(f\"Processing batch {batch_count}...\")  # 진행 상황 모니터링\n",
        "            inputs = {k: v.to(\"cuda\" if torch.cuda.is_available() else \"cpu\") for k, v in batch.items()}\n",
        "            labels = batch['labels'].to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "            outputs = model(**inputs)\n",
        "            total_val_loss += outputs.loss.item()\n",
        "    print(f\"Epoch {epoch + 1}, Validation Loss: {total_val_loss / 5}\")\n",
        "\n",
        "# 모델 및 토크나이저 저장\n",
        "model.save_pretrained(\"/content/pratice_GPT2/gpt2_emotion_classifier\")\n",
        "tokenizer.save_pretrained(\"/content/pratice_GPT2/gpt2_emotion_classifier\")"
      ],
      "metadata": {
        "id": "Xjkpce1Xv-th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. 학습된 모델 Inference(실행)\n",
        "\n",
        "아래는 학습된 모델을 실제 실행해볼 수 있는 코드입니다.\n",
        "\n",
        "본 과정에서는 다음을 수행합니다.\n",
        "\n",
        "1. 데이터셋 라벨 사전화\n",
        "2. 학습된 모델을 Inferece하는 함수 작성\n",
        "3. 텍스트 입력을 통한 모델 Inference\n",
        "\n",
        "우선 주어진 데이터셋의 라벨을 사전(Dictionary)화 하여, Index(키 값)이 들어오면 한글로 반환하게 합니다.\n",
        "\n",
        "사전이 필요한 이유는 모델의 출력이 텍스트가 아닌 60개 감정의 index(숫자) 이기 때문에 이를 텍스트로 매핑시켜 출력하는 과정이 필요합니다."
      ],
      "metadata": {
        "id": "Hq0qrY9dCeMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 주어진 텍스트 데이터\n",
        "text_data = [\n",
        "    [\"분노\", \"슬픔\", \"불안\", \"상처\", \"당황\", \"기쁨\"],\n",
        "    [\"툴툴대는\", \"실망한\", \"두려운\", \"질투하는\", \"고립된\", \"감사하는\"],\n",
        "    [\"좌절한\", \"비통한\", \"스트레스 받는\", \"배신당한\", \"남의 시선 의식하는\", \"사랑하는\"],\n",
        "    [\"짜증나는\", \"후회되는\", \"취약한\", \"고립된\", \"외로운\", \"편안한\"],\n",
        "    [\"방어적인\", \"우울한\", \"혼란스러운\", \"충격 받은\", \"열등감\", \"만족스러운\"],\n",
        "    [\"악의적인\", \"마비된\", \"당혹스러운\", \"불우한\", \"죄책감\", \"흥분되는\"],\n",
        "    [\"안달하는\", \"염세적인\", \"회의적인\", \"희생된\", \"부끄러운\", \"느긋한\"],\n",
        "    [\"구역질 나는\", \"눈물이 나는\", \"걱정스러운\", \"억울한\", \"혐오스러운\", \"안도하는\"],\n",
        "    [\"노여워하는\", \"낙담한\", \"조심스러운\", \"괴로워하는\", \"한심한\", \"신이 난\"],\n",
        "    [\"성가신\", \"환멸을 느끼는\", \"초조한\", \"버려진\", \"혼란스러운\", \"자신하는\"]\n",
        "]\n",
        "\n",
        "# 빈 딕셔너리 생성\n",
        "result_dict = {}\n",
        "\n",
        "# 텍스트 데이터를 기반으로 딕셔너리 생성\n",
        "for i, row in enumerate(text_data):\n",
        "    for j, emotion in enumerate(row):\n",
        "        index = i * len(row) + j + 1  # 1부터 시작하는 인덱스\n",
        "        result_dict[index] = emotion\n",
        "\n",
        "# 결과 딕셔너리 출력\n",
        "print(result_dict)"
      ],
      "metadata": {
        "id": "sZoiJmT0-sVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음은 감정 분류를 위한 GPT-2 모델을 이용하여 주어진 텍스트의 감정을 예측하는 코드입니다.\n",
        "\n",
        "아래는 텍스트가 주어졌을때 이를 학습된 모델을 통하여 예측하는 함수입니다."
      ],
      "metadata": {
        "id": "MD3oq4ND50ed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# 모델 및 토크나이저 로드\n",
        "model_path = \"/content/pratice_GPT2/gpt2_emotion_classifier/\"\n",
        "model = GPT2ForSequenceClassification.from_pretrained(model_path)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
        "\n",
        "# GPU 사용 가능 여부 확인\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "\n",
        "def predict_emotion(model, tokenizer, label_encoder, text):\n",
        "\n",
        "    # 모델을 평가 모드로 설정\n",
        "    model.eval()\n",
        "\n",
        "    # 텍스트 토큰화\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=100)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # 모델 추론\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "        predicted_class = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    return predicted_class"
      ],
      "metadata": {
        "id": "O9I0S1qR5uro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래의 코드에서 sample_text를 직접 작성하여 감정분류 모델의 출력을 확인해볼 수 있습니다."
      ],
      "metadata": {
        "id": "e8ul1dN4D0wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 텍스트로 감정 예측\n",
        "sample_text = \"친구들에게 큰맘 먹고 속마음을 고백했는데 갑자기 그 이후로 친구들이 나를 따돌렸어.\"\n",
        "predicted_emotion = predict_emotion(model, tokenizer, label_encoder, sample_text)\n",
        "print(f\"Predicted Emotion for '{sample_text} \\n: {result_dict[predicted_emotion]}\")"
      ],
      "metadata": {
        "id": "TcFY-Qlpwc3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이상으로 본 실습을 마치도록 하겠습니다.\n",
        "\n",
        "모두들 고생 많으셨습니다!\n",
        "\n",
        "![](https://img.favpng.com/10/1/7/kakaotalk-kakao-friends-emoticon-sticker-png-favpng-mZm2vp0mk2Ce9aTUnBjC4s4DZ.jpg)"
      ],
      "metadata": {
        "id": "Ax3YYWwzG4ge"
      }
    }
  ]
}