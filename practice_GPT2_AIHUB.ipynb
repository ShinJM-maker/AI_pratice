{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# colabì„ ì´ìš©í•œ Natural Language Processing(NLP) ì‹¤ìŠµ\n",
        "\n",
        "ğŸ¯ í•™ìŠµ ëª©í‘œ : colab í™˜ê²½ì—ì„œ NLP ëª¨ë¸ í•™ìŠµ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n",
        "\n",
        "- ì‹¤ìŠµ ì¬ë£Œ\n",
        "\n",
        "| í•­ëª© | ìƒì„¸ |\n",
        "| ---- | ---- |\n",
        "| ğŸ—‚ï¸ ë°ì´í„° | AI-HUBì˜ ê°ì„± ëŒ€í™” ë§ë­‰ì¹˜ ì¤‘ ìƒ˜í”Œ ë°ì´í„° |\n",
        "| ğŸ¤– NLP ì–¸ì–´ ëª¨ë¸ | GPT-2 (Generative pre-trained transformer-2) |\n",
        "| ğŸ—ï¸ NLP í•™ìŠµ í”„ë ˆì„ì›Œí¬ | torch |\n",
        "| ğŸ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ | Python |\n",
        "| ğŸ‘©â€ğŸ’» í”„ë¡œê·¸ë˜ë° í™˜ê²½ | Colab |\n",
        "\n",
        "\n",
        "- colabì—ì„œ ì½”ë“œ ì‹¤í–‰ ë°©ë²•ì€ ë‹¤ìŒ ê·¸ë¦¼ì„ ì°¸ì¡°í•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
        "    ![](https://i.imgur.com/0GoFr7q.png)"
      ],
      "metadata": {
        "id": "7qnLQFBp6paB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬\n",
        "\n",
        "ì´ë²ˆ ì‹¤ìŠµì—ì„œ ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ëŠ” AI-HUBì˜ ì¹˜ë§¤ ê°ì„± ëŒ€í™” ë§ë­‰ì¹˜ ì¤‘ ìƒ˜í”Œ ë°ì´í„° ì§‘í•© ì¤‘ ì¸ì§€ê¸°ëŠ¥ ë°ì´í„°ì˜ ìƒ˜í”Œ ìë£Œë¥¼ ì´ìš©í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì‹¤ìŠµ ë°ì´í„° ì§‘í•©ì— ëŒ€í•œ ëª…ì„¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
        "\n",
        "- ë°ì´í„° ê°œìˆ˜ : 19,920ê°œ\n",
        "- ì£¼ìš” í•­ëª©\n",
        "  - persona: ëŒ€í™”ìì˜ í˜ë¥´ì†Œë‚˜ ì •ë³´\n",
        "  - emotion: ê°ì • ì •ë³´(ìš°ë¦¬ê°€ ì˜ˆì¸¡í•˜ê³ ì í•˜ëŠ” íƒ€ê²Ÿ)\n",
        "  - talk: ëŒ€í™” ë‚´ìš©\n",
        "    - content: ëŒ€í™” ë‚´ìš© (HS01, SS01, ...)\n",
        "\n",
        "ìš°ë¦¬ê°€ ì›í•˜ëŠ” ê²ƒì€ ê° ëŒ€í™”(HS01, SS01, ...)ì˜ ë‚´ìš©ê³¼ ê·¸ì— í•´ë‹¹í•˜ëŠ” ê°ì •(emotionì˜ type)ì…ë‹ˆë‹¤. ë”°ë¼ì„œ ì´ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ì „ì²˜ë¦¬ë¥¼ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "hYpgisno_bYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ShinJM-maker/pratice_GPT2.git"
      ],
      "metadata": {
        "id": "TOSesHRI2wgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZn-dCQFTnb5"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# ë¡œì»¬ì—ì„œ JSON íŒŒì¼ ì½ê¸°\n",
        "file_path = \"/content/pratice_GPT2/ê°ì„±ëŒ€í™”ë§ë­‰ì¹˜(ìµœì¢…ë°ì´í„°)_Validation.json\"  # ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½í•´ì£¼ì„¸ìš”\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Extracting relevant data for emotion classification\n",
        "texts = []\n",
        "labels = []\n",
        "\n",
        "for entry in data:\n",
        "    emotion = entry['profile']['emotion']['type']\n",
        "\n",
        "    # Extracting all the dialogues\n",
        "    for key, dialogue in entry['talk']['content'].items():\n",
        "        if key.startswith('HS'):  # We'll only consider human dialogues for simplicity\n",
        "            texts.append(dialogue)\n",
        "            labels.append(emotion)\n",
        "\n",
        "# Checking the first few entries\n",
        "texts[100:105], labels[100:105]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ìœ„ ì½”ë“œì˜ ì‹¤í–‰ìœ¼ë¡œ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤. ê° ëŒ€í™” ë‚´ìš©(texts)ê³¼ í•´ë‹¹ ëŒ€í™”ì˜ ê°ì • ë¼ë²¨(labels)ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ í•™ìŠµìš©ê³¼ ê²€ì¦ìš©ìœ¼ë¡œ ë‚˜ëˆ„ê² ìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "vJ-TpYWnAoVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the data into training and validation sets\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "len(train_texts), len(val_texts)\n"
      ],
      "metadata": {
        "id": "rFak2t41UMFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë°ì´í„°ë¥¼ í•™ìŠµìš©(15,936ê°œ)ê³¼ ê²€ì¦ìš©(3,984ê°œ)ìœ¼ë¡œ ë‚˜ëˆ´ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì•„ë˜ëŠ” AI-HUBì˜ ê°ì„± ëŒ€í™” ë§ë­‰ì¹˜ì˜ ë¼ë²¨ ëª©ë¡ì…ë‹ˆë‹¤.\n",
        "\n",
        "![Image Alt Text](https://drive.google.com/uc?export=view&id=1fzxQIpz21nOc8G1nP8AFuERijwoUodaV)\n",
        "\n",
        "\n",
        "ì•„ë˜ëŠ” ë°ì´í„°ì…‹ì˜ ë¼ë²¨ë³„ ê°œìˆ˜ë¥¼ ì‹œê°í™” í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "aWbTWXZg_da0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Count the occurrences of each label in the training set\n",
        "label_distribution = Counter(train_labels)\n",
        "#print(label_distribution)\n",
        "sorted_label_distribution = dict(sorted(label_distribution.items(), key=lambda item: int(item[0][1:])))\n",
        "print(sorted_label_distribution)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract labels and their counts\n",
        "labels = list(sorted_label_distribution.keys())\n",
        "counts = list(sorted_label_distribution.values())\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(15, 7))  # Set the figure size for better visibility\n",
        "plt.bar(labels, counts, color='blue')\n",
        "plt.xlabel('Emotion Labels')\n",
        "plt.ylabel('Number of Occurrences')\n",
        "plt.title('Distribution of Emotion Labels')\n",
        "plt.xticks(rotation=90)  # Rotate x-axis labels for better visibility\n",
        "plt.tight_layout()  # Adjust layout for better visibility\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ntFAqWscy6ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. GPT-2 ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë”©\n",
        "\n",
        "ë‹¤ìŒ ë‹¨ê³„ë¡œ, GPT-2 ëª¨ë¸ ë° í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë”©í•˜ê² ìŠµë‹ˆë‹¤. Google Colabì—ì„œ ì‹¤í–‰í•  ë•Œ, ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ëª¨ë¸ ë¡œë”©ì„ ìœ„í•œ ì½”ë“œë¥¼ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ë³¸ ê³¼ì •ì—ì„œëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "\n",
        "1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "2. GPT-2 í† í¬ë‚˜ì´ì € ë¡œë”©\n",
        "3. ë¼ë²¨ ì¸ì½”ë”© ë° í…ìŠ¤íŠ¸ í† í°í™”\n",
        "4. PyTorch ë°ì´í„°ì…‹ìœ¼ë¡œ ë³€í™˜\n",
        "5. GPT-2 ëª¨ë¸ ë¡œë”© ë° ë¶„ë¥˜ í—¤ë“œ ì¶”ê°€\n",
        "6. í•™ìŠµ ì„¤ì •\n",
        "\n"
      ],
      "metadata": {
        "id": "H4CQmnjWA0_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì•„ë˜ì˜ ì½”ë“œì—ì„œ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
        "1. accelerate\n",
        "2. transformers"
      ],
      "metadata": {
        "id": "cMoetBzaEHwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall accelerate -y\n",
        "!pip install accelerate\n",
        "\n",
        "!pip install transformers[torch] -U"
      ],
      "metadata": {
        "id": "y4XtwJyOEGjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í–ˆë‹¤ë©´ ì´ì œ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë”©í•˜ê³  í•™ìŠµì„ ìœ„í•œ ì„¤ì •ì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì•„ë˜ ì½”ë“œë¥¼ í†µí•´ ê°ì • ë¶„ë¥˜ ì‘ì—…ì„ ìœ„í•´ GPT-2 ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.\n",
        "ìš°ë¦¬ëŠ” GPT-2 ëª¨ë¸ì„ í™œìš©í•˜ê³  ë¶„ë¥˜ ì‘ì—…ì„ ìœ„í•´ ì‹œí€€ìŠ¤ ë¶„ë¥˜ í—¤ë“œë¥¼ ì¶”ê°€í•¨ìœ¼ë¡œì¨ ì´ë¥¼ ì ìš©ì‹œí‚¬ ê²ƒì…ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "stX8DKPLEPG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, AdamW\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# í† í°í™”: GPT-2 í† í°í™”ê¸°ë¥¼ ë¡œë“œí•˜ì—¬ ì‹œì‘í•©ë‹ˆë‹¤.\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "#ë¼ë²¨ ì¸ì½”ë”©: ë¶„ë¥˜ ì‘ì—…ì„ ìœ„í•´ ë¬¸ìì—´ ë¼ë²¨ì„ ì •ìˆ˜ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "combined_labels = train_labels + val_labels\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(combined_labels)\n",
        "\n",
        "train_enc_labels = label_encoder.transform(train_labels)\n",
        "val_enc_labels = label_encoder.transform(val_labels)\n",
        "\n",
        "# í…ìŠ¤íŠ¸ ì¸ì½”ë”©: GPT-2 í† í°í™”ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=100)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=100)\n",
        "\n",
        "# PyTorch ë°ì´í„°ì…‹ ìƒì„±: ë°ì´í„°ê°€ í† í°í™”ë˜ë©´ ì´ë¥¼ PyTorch Datasetìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "class EmotionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = EmotionDataset(train_encodings, train_enc_labels)\n",
        "val_dataset = EmotionDataset(val_encodings, val_enc_labels)\n",
        "\n",
        "# ëª¨ë¸ ì´ˆê¸°í™”: ì‹œí€€ìŠ¤ ë¶„ë¥˜ í—¤ë“œê°€ ìˆëŠ” ì‚¬ì „ í›ˆë ¨ëœ GPT-2 ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.\n",
        "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2-medium\", num_labels=len(set(combined_labels)))\n",
        "\n",
        "# ëª¨ë¸ êµ¬ì„±: í† í°í™”ê¸°ì— íŒ¨ë”© í† í°ì„ ì„¤ì •í•œ ê²ƒì²˜ëŸ¼ ëª¨ë¸ì—ê²Œë„ ì´ íŒ¨ë”© í† í°ì— ëŒ€í•´ ì•Œë ¤ì•¼ í•©ë‹ˆë‹¤.\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# í›ˆë ¨ ì„¤ì •: ìš°ë¦¬ëŠ” ì˜¤ë¥˜ë¥¼ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ í›ˆë ¨ ì¤‘ì— ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•˜ëŠ” ìµœì í™”ê¸°ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8)\n"
      ],
      "metadata": {
        "id": "ClpIt17vURwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. GPT-2ë¥¼ í™œìš©í•œ ê°ì • ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€\n",
        "\n",
        "ì´ ì„¹ì…˜ì—ì„œëŠ” GPT-2 ê°ì • ë¶„ë¥˜ ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  í‰ê°€í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¹ë‹ˆë‹¤. ìš°ë¦¬ëŠ” í›ˆë ¨ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ê³ , ê²€ì¦ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
        "\n",
        "ë³¸ ê³¼ì •ì—ì„œëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "\n",
        "1. í›ˆë ¨ ëª¨ë“œ ì„¤ì •\n",
        "2. í›ˆë ¨ ë£¨í”„\n",
        "3. í‰ê°€ ëª¨ë“œ ì„¤ì •\n",
        "4. ëª¨ë¸ í‰ê°€\n",
        "5. ëª¨ë¸ ë° í† í°í™”ê¸° ì €ì¥\n",
        "\n",
        "ì›ë˜ëŠ” ì—¬ëŸ¬ í•™ìŠµ epochë¥¼ ì§„í–‰í•´ì•¼ í•˜ì§€ë§Œ, ì‹¤ìŠµì„ ê°„ëµí•˜ê²Œ ì§„í–‰í•˜ê¸° ìœ„í•´ 1 epochì™€ 10 batchë§Œìœ¼ë¡œ í•™ìŠµì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "xWO71tL3B7MD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# ë³´ë‹¤ ë¹ ë¥¸ í•™ìŠµì„ ìœ„í•´ 1 epochë§Œ ì‹¤í–‰í•˜ëŠ” í•™ìŠµ ë£¨í”„\n",
        "for epoch in range(1):\n",
        "    model.train()  # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì •\n",
        "    total_train_loss = 0\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        optimizer.zero_grad()  # ê·¸ë¼ë””ì–¸íŠ¸ ì´ˆê¸°í™”\n",
        "        # ì…ë ¥ ë°ì´í„° GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ì— ë”°ë¼ ì„¤ì •\n",
        "        inputs = {k: v.to(\"cuda\" if torch.cuda.is_available() else \"cpu\") for k, v in batch.items()}\n",
        "        outputs = model(**inputs)  # ëª¨ë¸ì— ì…ë ¥ ë°ì´í„° ì „ë‹¬\n",
        "        loss = outputs.loss  # ì†ì‹¤ ê°’\n",
        "        total_train_loss += loss.item()  # ì´ í•™ìŠµ ì†ì‹¤ì— ì¶”ê°€\n",
        "        loss.backward()  # ì—­ì „íŒŒ\n",
        "        optimizer.step()  # ìµœì í™” ìˆ˜í–‰\n",
        "\n",
        "        print(f\"Batch {batch_idx}, Training Loss: {total_train_loss / (batch_idx + 1)}\")\n",
        "        if batch_idx == 10:\n",
        "            break\n",
        "\n",
        "    # ëª¨ë¸ í‰ê°€\n",
        "    model.eval()  # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
        "    total_val_loss = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    batch_count = 0  # ë°°ì¹˜ ìˆ˜ ì œí•œìš© ë³€ìˆ˜\n",
        "    with torch.no_grad():  # ê·¸ë¼ë””ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™”\n",
        "        for batch in val_loader:\n",
        "            batch_count += 1\n",
        "            # ë””ë²„ê¹…ì„ ìœ„í•´ ì²˜ìŒ 5ê°œ ë°°ì¹˜ë§Œ ì²˜ë¦¬\n",
        "            if batch_count > 5:\n",
        "                break\n",
        "\n",
        "            print(f\"Processing batch {batch_count}...\")  # ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§\n",
        "            inputs = {k: v.to(\"cuda\" if torch.cuda.is_available() else \"cpu\") for k, v in batch.items()}\n",
        "            labels = batch['labels'].to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "            outputs = model(**inputs)\n",
        "            total_val_loss += outputs.loss.item()\n",
        "    print(f\"Epoch {epoch + 1}, Validation Loss: {total_val_loss / 5}\")\n",
        "\n",
        "# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì €ì¥\n",
        "model.save_pretrained(\"/content/pratice_GPT2/gpt2_emotion_classifier\")\n",
        "tokenizer.save_pretrained(\"/content/pratice_GPT2/gpt2_emotion_classifier\")"
      ],
      "metadata": {
        "id": "Xjkpce1Xv-th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. í•™ìŠµëœ ëª¨ë¸ Inference(ì‹¤í–‰)\n",
        "\n",
        "ì•„ë˜ëŠ” í•™ìŠµëœ ëª¨ë¸ì„ ì‹¤ì œ ì‹¤í–‰í•´ë³¼ ìˆ˜ ìˆëŠ” ì½”ë“œì…ë‹ˆë‹¤.\n",
        "\n",
        "ë³¸ ê³¼ì •ì—ì„œëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "\n",
        "1. ë°ì´í„°ì…‹ ë¼ë²¨ ì‚¬ì „í™”\n",
        "2. í•™ìŠµëœ ëª¨ë¸ì„ Infereceí•˜ëŠ” í•¨ìˆ˜ ì‘ì„±\n",
        "3. í…ìŠ¤íŠ¸ ì…ë ¥ì„ í†µí•œ ëª¨ë¸ Inference\n",
        "\n",
        "ìš°ì„  ì£¼ì–´ì§„ ë°ì´í„°ì…‹ì˜ ë¼ë²¨ì„ ì‚¬ì „(Dictionary)í™” í•˜ì—¬, Index(í‚¤ ê°’)ì´ ë“¤ì–´ì˜¤ë©´ í•œê¸€ë¡œ ë°˜í™˜í•˜ê²Œ í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì‚¬ì „ì´ í•„ìš”í•œ ì´ìœ ëŠ” ëª¨ë¸ì˜ ì¶œë ¥ì´ í…ìŠ¤íŠ¸ê°€ ì•„ë‹Œ 60ê°œ ê°ì •ì˜ index(ìˆ«ì) ì´ê¸° ë•Œë¬¸ì— ì´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë§¤í•‘ì‹œì¼œ ì¶œë ¥í•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "Hq0qrY9dCeMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ ë°ì´í„°\n",
        "text_data = [\n",
        "    [\"ë¶„ë…¸\", \"ìŠ¬í””\", \"ë¶ˆì•ˆ\", \"ìƒì²˜\", \"ë‹¹í™©\", \"ê¸°ì¨\"],\n",
        "    [\"íˆ´íˆ´ëŒ€ëŠ”\", \"ì‹¤ë§í•œ\", \"ë‘ë ¤ìš´\", \"ì§ˆíˆ¬í•˜ëŠ”\", \"ê³ ë¦½ëœ\", \"ê°ì‚¬í•˜ëŠ”\"],\n",
        "    [\"ì¢Œì ˆí•œ\", \"ë¹„í†µí•œ\", \"ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ëŠ”\", \"ë°°ì‹ ë‹¹í•œ\", \"ë‚¨ì˜ ì‹œì„  ì˜ì‹í•˜ëŠ”\", \"ì‚¬ë‘í•˜ëŠ”\"],\n",
        "    [\"ì§œì¦ë‚˜ëŠ”\", \"í›„íšŒë˜ëŠ”\", \"ì·¨ì•½í•œ\", \"ê³ ë¦½ëœ\", \"ì™¸ë¡œìš´\", \"í¸ì•ˆí•œ\"],\n",
        "    [\"ë°©ì–´ì ì¸\", \"ìš°ìš¸í•œ\", \"í˜¼ë€ìŠ¤ëŸ¬ìš´\", \"ì¶©ê²© ë°›ì€\", \"ì—´ë“±ê°\", \"ë§Œì¡±ìŠ¤ëŸ¬ìš´\"],\n",
        "    [\"ì•…ì˜ì ì¸\", \"ë§ˆë¹„ëœ\", \"ë‹¹í˜¹ìŠ¤ëŸ¬ìš´\", \"ë¶ˆìš°í•œ\", \"ì£„ì±…ê°\", \"í¥ë¶„ë˜ëŠ”\"],\n",
        "    [\"ì•ˆë‹¬í•˜ëŠ”\", \"ì—¼ì„¸ì ì¸\", \"íšŒì˜ì ì¸\", \"í¬ìƒëœ\", \"ë¶€ë„ëŸ¬ìš´\", \"ëŠê¸‹í•œ\"],\n",
        "    [\"êµ¬ì—­ì§ˆ ë‚˜ëŠ”\", \"ëˆˆë¬¼ì´ ë‚˜ëŠ”\", \"ê±±ì •ìŠ¤ëŸ¬ìš´\", \"ì–µìš¸í•œ\", \"í˜ì˜¤ìŠ¤ëŸ¬ìš´\", \"ì•ˆë„í•˜ëŠ”\"],\n",
        "    [\"ë…¸ì—¬ì›Œí•˜ëŠ”\", \"ë‚™ë‹´í•œ\", \"ì¡°ì‹¬ìŠ¤ëŸ¬ìš´\", \"ê´´ë¡œì›Œí•˜ëŠ”\", \"í•œì‹¬í•œ\", \"ì‹ ì´ ë‚œ\"],\n",
        "    [\"ì„±ê°€ì‹ \", \"í™˜ë©¸ì„ ëŠë¼ëŠ”\", \"ì´ˆì¡°í•œ\", \"ë²„ë ¤ì§„\", \"í˜¼ë€ìŠ¤ëŸ¬ìš´\", \"ìì‹ í•˜ëŠ”\"]\n",
        "]\n",
        "\n",
        "# ë¹ˆ ë”•ì…”ë„ˆë¦¬ ìƒì„±\n",
        "result_dict = {}\n",
        "\n",
        "# í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë”•ì…”ë„ˆë¦¬ ìƒì„±\n",
        "for i, row in enumerate(text_data):\n",
        "    for j, emotion in enumerate(row):\n",
        "        index = i * len(row) + j + 1  # 1ë¶€í„° ì‹œì‘í•˜ëŠ” ì¸ë±ìŠ¤\n",
        "        result_dict[index] = emotion\n",
        "\n",
        "# ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ì¶œë ¥\n",
        "print(result_dict)"
      ],
      "metadata": {
        "id": "sZoiJmT0-sVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë‹¤ìŒì€ ê°ì • ë¶„ë¥˜ë¥¼ ìœ„í•œ GPT-2 ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ì˜ˆì¸¡í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.\n",
        "\n",
        "ì•„ë˜ëŠ” í…ìŠ¤íŠ¸ê°€ ì£¼ì–´ì¡Œì„ë•Œ ì´ë¥¼ í•™ìŠµëœ ëª¨ë¸ì„ í†µí•˜ì—¬ ì˜ˆì¸¡í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "MD3oq4ND50ed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
        "model_path = \"/content/pratice_GPT2/gpt2_emotion_classifier/\"\n",
        "model = GPT2ForSequenceClassification.from_pretrained(model_path)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
        "\n",
        "# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "\n",
        "def predict_emotion(model, tokenizer, label_encoder, text):\n",
        "\n",
        "    # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
        "    model.eval()\n",
        "\n",
        "    # í…ìŠ¤íŠ¸ í† í°í™”\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=100)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # ëª¨ë¸ ì¶”ë¡ \n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "        predicted_class = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    return predicted_class"
      ],
      "metadata": {
        "id": "O9I0S1qR5uro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì•„ë˜ì˜ ì½”ë“œì—ì„œ sample_textë¥¼ ì§ì ‘ ì‘ì„±í•˜ì—¬ ê°ì •ë¶„ë¥˜ ëª¨ë¸ì˜ ì¶œë ¥ì„ í™•ì¸í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "e8ul1dN4D0wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì˜ˆì œ í…ìŠ¤íŠ¸ë¡œ ê°ì • ì˜ˆì¸¡\n",
        "sample_text = \"ì¹œêµ¬ë“¤ì—ê²Œ í°ë§˜ ë¨¹ê³  ì†ë§ˆìŒì„ ê³ ë°±í–ˆëŠ”ë° ê°‘ìê¸° ê·¸ ì´í›„ë¡œ ì¹œêµ¬ë“¤ì´ ë‚˜ë¥¼ ë”°ëŒë ¸ì–´.\"\n",
        "predicted_emotion = predict_emotion(model, tokenizer, label_encoder, sample_text)\n",
        "print(f\"Predicted Emotion for '{sample_text} \\n: {result_dict[predicted_emotion]}\")"
      ],
      "metadata": {
        "id": "TcFY-Qlpwc3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì´ìƒìœ¼ë¡œ ë³¸ ì‹¤ìŠµì„ ë§ˆì¹˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ëª¨ë‘ë“¤ ê³ ìƒ ë§ìœ¼ì…¨ìŠµë‹ˆë‹¤!\n",
        "\n",
        "![](https://img.favpng.com/10/1/7/kakaotalk-kakao-friends-emoticon-sticker-png-favpng-mZm2vp0mk2Ce9aTUnBjC4s4DZ.jpg)"
      ],
      "metadata": {
        "id": "Ax3YYWwzG4ge"
      }
    }
  ]
}